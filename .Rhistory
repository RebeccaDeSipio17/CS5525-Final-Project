setwd("C:\Users\Rebecca\Documents\Virginia_Tech\FA21\CS5525\Homework\HW4")
setwd("C:/Users/Rebecca/Documents/Virginia_Tech/FA21/CS5525/Homework/HW4")
challenger <- read.delim("challenger.txt")
str(challenger)
library(dplyr)
challenger <- read.delim("challenger.txt")
str(challenger)
nasa1 <- glm(fail.field ~ temp, family="binomia", data=challenger)
nasa1 <- glm(fail.field ~ temp, family="binomial", data=challenger)
R_sq_1 = 1 - nasa1$deviance/nasa1$null.deviance
BIC_1  = nasa1$deviance + 2 * log(dim(challenger))
(R_sq_1 = 1 - nasa1$deviance/nasa1$null.deviance)
(BIC_1  = nasa1$deviance + 2 * log(dim(challenger)))
(R_sq_1 = 1 - nasa1$deviance/nasa1$null.deviance)
(BIC_1  = nasa1$deviance + 2 * log(dim(challenger)[1]))
# Analyze model 2: fail.field ~ temp + pres.field
nasa2 <- glm(fail.field ~ temp + pres.field, family = "binomial", data=challenger)
(R_sq_2 = 2 - nasa2$deviance/nasa2$null.deviance)
(BIC_2  = nasa2$deviance + 2 * log(dim(challenger)[1]))
# Analyze model 3: fail.field ~ temp + pres.field + pres.nozzle
nasa3 <- glm(fail.field ~ temp + pres.field + pres.nozzle, family = "binomial", data=challenger)
(R_sq_3 = 2 - nasa3$deviance/nasa3$null.deviance)
(BIC_2  = nasa3$deviance + 2 * log(dim(challenger)[1]))
# Analyze model 2: fail.field ~ temp + pres.field
nasa2 <- glm(fail.field ~ temp + pres.field, family = "binomial", data=challenger)
(R_sq_2 = 1 - nasa2$deviance/nasa2$null.deviance)
(BIC_2  = nasa2$deviance + 2 * log(dim(challenger)[1]))
# Analyze model 3: fail.field ~ temp + pres.field + pres.nozzle
nasa3 <- glm(fail.field ~ temp + pres.field + pres.nozzle, family = "binomial", data=challenger)
(R_sq_3 = 1 - nasa3$deviance/nasa3$null.deviance)
(BIC_3  = nasa3$deviance + 2 * log(dim(challenger)[1]))
?coef
coef(nasa3)
(nasa3_coef = nasa3$coefficients)
Bvals <- seq(250,2500,250) # 10 different sample sizes
VMn1 <- c()
VMn2 <- c()
# first seed
set.seed(100)
n <- rcauchy(21) # get a set of n=21 numbers from Cauchy distribution
for (B in Bvals){
resamples <- lapply(1:B, function(i) sample(n, replace=T)) #perform bootstrapping
# calculate the median for each bootstrap samples
r.median <- sapply(resamples, median)
VMn1 <- append(VMn1,var(r.median)) # compute the bootstrap approximation
}
for (B in Bvals){
resamples <- lapply(1:B, function(i) sample(n, replace=T)) #perform bootstrapping
# calculate the median for each bootstrap samples
r.median <- sapply(resamples, median)
VMn1 <- append(VMn1,var(r.median)) # compute the bootstrap approximation
}
# second seed
set.seed(200)
# second seed
set.seed(200)
n <- rcauchy(21) # get a set of n=21 numbers from Cauchy distribution
for (B in Bvals){
resamples <- lapply(1:B, function(i) sample(n, replace=T)) #perform bootstrapping
# calculate the median for each bootstrap samples
r.median <- sapply(resamples, median)
VMn2 <- append(VMn2,var(r.median)) # compute the bootstrap approximation
}
for (B in Bvals){
resamples <- lapply(1:B, function(i) sample(n, replace=T)) #perform bootstrapping
# calculate the median for each bootstrap samples
r.median <- sapply(resamples, median)
VMn2 <- append(VMn2,var(r.median)) # compute the bootstrap approximation
}
From the above calculations, we get the following results:
`set.seed(100)`, `Bvals = [250,500,750,1000,1250,1500,1750,2000,2250,2500]`:
```{r}
VMn1
```
`set.seed(200)`, `Bvals = [250,500,750,1000,1250,1500,1750,2000,2250,2500]`:
```{r}
VMn2
```
VMn1
VMn2
set.seed(123)
library(tree)
install.packages("tree")
library(tree)
library(ISLR)
install.packages("ISLR")
library(ISLR)
attach(Carseats)
summary(Carseats)
Sale <- select(Sales)
library(dplyr)
summary(Carseats)
Sale <- select(Sales)
Sale <- Carseats(select(Sales))
sales <- Sales
sales
# split data into training set and test set
train=sample(1:nrow(Sales), 200)
Sales=Sales[-train,]
length(Carseats)
nrow(Carseats)
nrow(Sales)
nrow(Carseats(Sales))
nrow(sales)
?nrow
Sales
Carseats
# Load in libraries
library(glmnet)
# Load in the data
dat <- readRDS("Scheetz2006.rds")
attach(dat)
dim(dat$X)
# split data into training set and test set
train=sample(1:nrow(Carseats), 200)
Carseats.test=Carseats[-train,]
High.test=High[-train]
High=ifelse(Sales<=8,"No","Yes")
High=as.factor(ifelse(Sales<=8,"No","Yes"))
# split data into training set and test set
train=sample(1:nrow(Carseats), 200)
Carseats.test=Carseats[-train,]
High.test=High[-train]
# Fit a regression tree and plot the results
tree.car=tree(Sales~.,Carseats,subset=train)
summary(tree.car)
plot(tree.car, type = "unif")
text(tree.car,pretty=0,cex=0.7)
# obtain test MSE
pred=predict(tree.car,newdata=Carseats[-train,])
car.test=Carseats[-train,"Sales"]
(test.MSE <- mean((pred-car.test)^2))
## Problem 3
# Use cross validation to determine the optimal level of tree complexity
cv.car=cv.tree(tree.car)
cv.car
plot(cv.car)
# Prune the tree
prune.car=prune.tree(tree.car,best=9)
plot(prune.car,type = "unif")
text(prune.car,pretty=0,cex=0.7)
# Recalculate test MSE
# obtain test MSE
pred2=predict(tree.car,newdata=Carseats[-train,])
car.test2=Carseats[-train,"Sales"]
(test.MSE <- mean((pred2-car.test2)^2))
# Prune the tree
prune.car=prune.tree(tree.car,best=9)
plot(prune.car,type = "unif")
text(prune.car,pretty=0,cex=0.7)
## Problem 3
# Use cross validation to determine the optimal level of tree complexity
cv.car=cv.tree(tree.car)
cv.car
plot(cv.car)
min(cv.car$dev)
which.min(cv.car$dev)
(size(13))
(size[13])
(cv.car$size[13])
## Problem 3
# Use cross validation to determine the optimal level of tree complexity
cv.car=cv.tree(tree.car)
cv.car
plot(cv.car)
which.min(cv.car$dev)
best_val <- (cv.car$size[13])
# Prune the tree
prune.car=prune.tree(tree.car,best=best_val)
plot(prune.car,type = "unif")
text(prune.car,pretty=0,cex=0.7)
which.min(cv.car$dev)
# Recalculate test MSE
# obtain test MSE
pred2=predict(tree.car,newdata=Carseats[-train,])
car.test2=Carseats[-train,"Sales"]
(test.MSE <- mean((pred2-car.test2)^2))
# Recalculate test MSE
# obtain test MSE
pred2=predict(cv.car),newdata=Carseats[-train,])
# Recalculate test MSE
# obtain test MSE
pred2=predict(cv.car,newdata=Carseats[-train,])
# Recalculate test MSE
# obtain test MSE
pred2=predict(prune.car,newdata=Carseats[-train,])
(test.MSE <- mean((pred2-car.test2)^2))
set.seed(123)
library(dplyr)
library(tree)
library(ISLR)
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
High=as.factor(ifelse(Sales<=8,"No","Yes"))
# split data into training set and test set
train=sample(1:nrow(Carseats), 200)
Carseats.test=Carseats[-train,]
High.test=High[-train]
## Problem 2
# Fit a regression tree and plot the results
set.seed(123)
tree.car=tree(Sales~.,Carseats,subset=train)
summary(tree.car)
plot(tree.car, type = "unif")
text(tree.car,pretty=0,cex=0.7)
# obtain test MSE
pred=predict(tree.car,newdata=Carseats[-train,])
car.test=Carseats[-train,"Sales"]
(test.MSE <- mean((pred-car.test)^2))
## Problem 3
# Use cross validation to determine the optimal level of tree complexity
set.seed(123)
cv.car=cv.tree(tree.car)
cv.car
plot(cv.car)
which.min(cv.car$dev)
best_val <- (cv.car$size[13])
# Prune the tree
set.seed(123)
prune.car=prune.tree(tree.car,best=best_val)
plot(prune.car,type = "unif")
text(prune.car,pretty=0,cex=0.7)
# Recalculate test MSE
# obtain test MSE
pred2=predict(prune.car,newdata=Carseats[-train,])
(test.MSE <- mean((pred2-car.test2)^2))
# Recalculate test MSE
# obtain test MSE
pred2=predict(prune.car,newdata=Carseats[-train,])
(test.MSE <- mean((pred2-car.test)^2))
str(Boston)
attach(Boston)
str(Carsetas)
str(Carseats)
## Problem 4
# Use the bagging approach to analyze this data
bag.car=randomForest(medv~.,data=Carseats,subset=train,mtry=11,importance=TRUE)
install.packages("randomForest")
## Problem 4
library(randonForest)
# Use the bagging approach to analyze this data
bag.car=randomForest(medv~.,data=Carseats,subset=train,mtry=11,importance=TRUE)
## Problem 4
library(randomForest)
# Use the bagging approach to analyze this data
bag.car=randomForest(medv~.,data=Carseats,subset=train,mtry=11,importance=TRUE)
?randomForest
# Use the bagging approach to analyze this data
set.seed(123)
bag.car=randomForest(Sales~.,data=Carseats,subset=train,mtry=10,importance=TRUE)
bag.car
# Test MSE
pred3=predict(bag.car,newdata=Carseats[-train,])
(test.MSE <- mean((pred3-car.test)^2))
# use the importance function to determine which variables are most important
importance(bag.car)
## Problem 5
# Use random forest to analyze this data (use p/3 for regression)
rf.boston=randomForest(Sales~.,data=Carseats,subset=train,mtry=4,importance=TRUE)
## Problem 5
# Use random forest to analyze this data (use p/3 for regression)
rf.car=randomForest(Sales~.,data=Carseats,subset=train,mtry=4,importance=TRUE)
rf.car
# test MSE
pred4=predict(rf.car,newdata=Carseats[-train,])
(test.MSE <- mean((pred4-car.test)^2))
# use the importance function to determine which variables are most important
importance(rf.car)
# describe the effect of 'm', the number of variables considered at each split, on the error rate obtained
# try a couple different m values
rf.car.2=randomForest(Sales~.,data=Carseats,subset=train,mtry=2,importance=TRUE)
rf.car.4=randomForest(Sales~.,data=Carseats,subset=train,mtry=4,importance=TRUE)
rf.car.6=randomForest(Sales~.,data=Carseats,subset=train,mtry=6,importance=TRUE)
rf.car.8=randomForest(Sales~.,data=Carseats,subset=train,mtry=8,importance=TRUE)
pred.2=predict(rf.car.2,newdata=Carseats[-train,])
pred.4=predict(rf.car.4,newdata=Carseats[-train,])
pred.6=predict(rf.car.6,newdata=Carseats[-train,])
pred.8=predict(rf.car.8,newdata=Carseats[-train,])
(test.MSE <- mean((pred.2-car.test)^2))
(test.MSE <- mean((pred.4-car.test)^2))
(test.MSE <- mean((pred.6-car.test)^2))
(test.MSE <- mean((pred.8-car.test)^2))
# describe the effect of 'm', the number of variables considered at each split, on the error rate obtained
# try a couple different m values
set.seed(123)
rf.car.2=randomForest(Sales~.,data=Carseats,subset=train,mtry=2,importance=TRUE)
set.seed(123)
rf.car.4=randomForest(Sales~.,data=Carseats,subset=train,mtry=4,importance=TRUE)
set.seed(123)
rf.car.6=randomForest(Sales~.,data=Carseats,subset=train,mtry=6,importance=TRUE)
set.seed(123)
rf.car.8=randomForest(Sales~.,data=Carseats,subset=train,mtry=8,importance=TRUE)
pred.2=predict(rf.car.2,newdata=Carseats[-train,])
pred.4=predict(rf.car.4,newdata=Carseats[-train,])
pred.6=predict(rf.car.6,newdata=Carseats[-train,])
pred.8=predict(rf.car.8,newdata=Carseats[-train,])
(test.MSE <- mean((pred.2-car.test)^2))
(test.MSE <- mean((pred.4-car.test)^2))
(test.MSE <- mean((pred.6-car.test)^2))
(test.MSE <- mean((pred.8-car.test)^2))
# describe the effect of 'm', the number of variables considered at each split, on the error rate obtained
# try a couple different m values
set.seed(123)
rf.car.2=randomForest(Sales~.,data=Carseats,subset=train,mtry=2,importance=TRUE)
rf.car.4=randomForest(Sales~.,data=Carseats,subset=train,mtry=4,importance=TRUE)
rf.car.6=randomForest(Sales~.,data=Carseats,subset=train,mtry=6,importance=TRUE)
rf.car.8=randomForest(Sales~.,data=Carseats,subset=train,mtry=8,importance=TRUE)
pred.2=predict(rf.car.2,newdata=Carseats[-train,])
pred.4=predict(rf.car.4,newdata=Carseats[-train,])
pred.6=predict(rf.car.6,newdata=Carseats[-train,])
pred.8=predict(rf.car.8,newdata=Carseats[-train,])
(test.MSE <- mean((pred.2-car.test)^2))
(test.MSE <- mean((pred.4-car.test)^2))
(test.MSE <- mean((pred.6-car.test)^2))
(test.MSE <- mean((pred.8-car.test)^2))
dti <- read.csv("DTI.csv")
str(dti)
min_z = min(dti$Zscore)
mid_z = mean(dti$Zscore)
max_z = max(dti$Zscore)
library(ggplot2)
ggplot(data = dti, aes(x = x, y = y, fill = Zscore)) + geom_tile(color = "grey") +
scale_fill_gradient2(low = "blue", high = "red", midpoint = mid_z,
limit = c(min_z, max_z), space = "Lab", name = "Colour bar") +
theme_light() + coord_fixed()
set.seed(2441139)
library(e1071)
# read data
heart <- read.csv("heart.csv")
Target <- as.factor(heart$target)
setwd("~/Virginia_Tech/FA21/CS5525/final_project/CS5525-Final-Project")
set.seed(2441139)
library(e1071)
# read data
heart <- read.csv("heart.csv")
Target <- as.factor(heart$target)
# split into training and test data
train <- sample(1:nrow(heart), 0.75*nrow(heart))
heart.test <- heart[-train, ]
Target.test <- Target[-train]
train
heart
Target
Target.test
dat <- data.fram(
x=train,
y=as.factor(Target.test)
)
dat <- data.frame(
x=train,
y=as.factor(Target.test)
)
x
train
heart.test
Target.test
dim(train)
dim(Target.test)
size(train)
dim(train)
trian
train
dim(heart.test)
dim(Target.test)
Target
Target.test
heart.train <- heart[train, ]
dat <- data.frame(
x=heart.train,
y=as.factor(Target.test)
)
dim(heart.train)
Target.test
train
dim(train)
dim(heart.train)
dim(heart.test)
Target.train <- Target[train, ]
Target.train <- Target[train]
Target.train
dim(Target.train)
dat <- data.frame(
x=heart.train,
y=as.factor(Target.train)
)
# SVM
out <- svm(y ~., data=dat, kernal="linear", cost=10)
summary(out)
table(out$fitted, dat$y)
# SVM
out <- svm(y ~., data=dat, kernal="radial", cost=10)
summary(out)
table(out$fitted, dat$y)
library(ISRL2)
library(IRSL2)
library(ISLR2)
names(Khan)
xtrai
xtrain
Khan
# test data
dat.test <- data.frame(
x = heart.test,
y = as.factor(Target.test)
)
pred.test <- predict(out, newdata = dat.test)
table(pred.test, dat.test$y)
